wandb: v4
name: in1k-mae-twob14--lr1e4-cls-5pc3
stage_name: logreg
vars:
  max_epochs: 50
  lr: 1.0e-4
  batch_size: 125
  drop_path_rate: 0.0
  pooling: class_token
  initializer:
    kind: pretrained_initializer
    weights_file: mae_twob14.pt
    use_checkpoint_kwargs: true

datasets:
  train:
    template: ${yaml:datasets/imagenet/train_minaug_smooth}
    template.vars.version: imagenet1k_msn5perclass_split3
  test:
    template: ${yaml:datasets/imagenet/test_noaug}
    template.vars.version: imagenet1k

model:
#  kind: vit.vit
#  patch_size: 16
#  kwargs: ${select:large:${yaml:models/vit}}
  pos_embed_is_learnable: true
  drop_path_rate: ${vars.drop_path_rate}
  drop_path_decay: true
  mode: classifier
  pooling:
    kind: ${vars.pooling}
  optim:
    kind: adamw
    lr: ${vars.lr}
    betas: [ 0.9, 0.999 ]
    weight_decay: 0.05
    schedule:
      - schedule:
          kind: linear_increasing_schedule
          exclude_first: true
          exclude_last: true
        end_epoch: 5
      - schedule:
          kind: cosine_decreasing_schedule
          exclude_last: true
    param_group_modifiers:
      - kind: layerwise_lr_decay_modifier
        decay: 0.75
  freezers:
    - kind: vit_block_freezer
      end_percent: 0.25
  initializers:
    - ${vars.initializer}

trainer:
  kind: classification_trainer
  precision: bfloat16
  backup_precision: float16
  max_epochs: ${vars.max_epochs}
  effective_batch_size: ${vars.batch_size}
  max_batch_size: 25
  log_every_n_epochs: 1
  callbacks:
    - kind: checkpoint_callback
    - kind: offline_accuracy_callback
      every_n_epochs: 1
      dataset_key: test
    - kind: best_checkpoint_callback
      every_n_epochs: 1
      metric_key: accuracy1/test/main